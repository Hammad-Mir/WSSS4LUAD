{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "513958dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ea6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_path = '/home/zephyr/Desktop/Newcastle_University/11_FP_D/Dataset/Dataset/1.training/1.training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693efc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1835c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_list(data_path):\n",
    "  # getting list of all the images\n",
    "  images = os.listdir(data_path)\n",
    "  exc_list = ['[1, 1, 0]', '[1, 0, 1]', '[0, 1, 1]', '[1, 1, 1]']\n",
    "  # setting the flag based on the image path\n",
    "  '''\n",
    "  if path == orig_image_path:\n",
    "    flag = 0\n",
    "  else:\n",
    "    flag = 1\n",
    "  '''\n",
    "  # don't need the flag, just resize all the images while loading to (224, 224)\n",
    "\n",
    "  # adding to the image_path_list\n",
    "  for i in images:\n",
    "    # adding the image path, flag and the label\n",
    "    #image_path_list[0].append([path + '/' + str(i), flag, list(map(int, i[-13:-4].strip('][').split(', ')))])\n",
    "    \n",
    "    if i[-13:-4] not in exc_list:\n",
    "      # adding the image path, and the label\n",
    "      image_path_list.append([data_path + '/' + str(i), list(map(int, i[-13:-4].strip('][').split(', ')))])\n",
    "    else:\n",
    "      continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8903450",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list(original_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e594026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4693"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8406fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dataset class for the data\n",
    "\n",
    "class LUAD(Dataset):\n",
    "  \"\"\"Lung Adenocarcinoma Histopathological images.\"\"\"\n",
    "  \n",
    "  def __init__(self, image_list, transform = None):\n",
    "    \n",
    "    \"\"\"\n",
    "      Args:\n",
    "        image_list: csv/list/numpy array containing image paths, flag and labels.\n",
    "        transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "    #Loading the csv file containing the image paths and one-hot encoded labels\n",
    "    #self.image_paths_labels = pd.read_csv(csv_file)\n",
    "    self.image_list = image_list\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.image_list)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    if torch.is_tensor(idx):\n",
    "      idx = idx.tolist()\n",
    "    \n",
    "    # code when input is a csv file\n",
    "    '''\n",
    "    image = cv2.imread(image_paths_labels.iloc[idx, 0])\n",
    "    image = transforms.ToTensor()(image)                # converts cv2 image (H, W, C) to pytorch tensor (C, H, W) do this in transforms\n",
    "    labels = self.image_paths_labels.iloc[idx, 1]\n",
    "    labels = np.array([labels])\n",
    "    labels = labels.astype('int').reshape(-1, 3)        # check what exactly to do with this\n",
    "    sample = {'image': image, 'labels': labels}\n",
    "    '''\n",
    "    #print(idx) keeps printing \n",
    "    # code when the input is a list of image paths and labels\n",
    "    image = cv2.imread(self.image_list[idx][0])\n",
    "    #image = transforms.ToTensor()(image)                # converts cv2 image (H, W, C) to pytorch tensor (C, H, W)\n",
    "    #labels = self.image_list[idx][1]\n",
    "    #labels = np.array([labels])\n",
    "    #labels = labels.astype('int').reshape(-1, 3) #.argmax(axis=1)        # reshapes the labels array into (n, 3) array\n",
    "    #labels = labels.astype('int').reshape(-1)\n",
    "    #sample = {'image': image, 'labels': labels}\n",
    "    \n",
    "    if self.transform:\n",
    "      #sample = self.transform(sample)\n",
    "      image = self.transform(image)\n",
    "    \n",
    "    return image#, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b902cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creatin the train dataset\n",
    "train_dataset = LUAD(image_path_list,\n",
    "                     transforms.Compose([transforms.ToTensor(),\n",
    "                                         transforms.Resize((224, 224)),\n",
    "                                        ]\n",
    "                                       ),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74373904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataloader\n",
    "dataloader = DataLoader(train_dataset,\n",
    "                        batch_size = 5,\n",
    "                        shuffle = False,\n",
    "                        num_workers = 1,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99e44ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0.\n",
    "std = 0.\n",
    "nb_samples = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "706cc705",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in dataloader:\n",
    "    batch_samples = data.size(0)\n",
    "    data = data.view(batch_samples, data.size(1), -1)\n",
    "    mean += data.mean(2).sum(0)\n",
    "    std += data.std(2).sum(0)\n",
    "    nb_samples += batch_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d09da098",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean /= nb_samples\n",
    "std /= nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4f293b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6974, 0.5352, 0.7675])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54c3d319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1336, 0.1921, 0.1492])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2f5a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
