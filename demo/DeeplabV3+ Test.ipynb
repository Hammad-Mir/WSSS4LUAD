{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9509e08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchsummary\n",
    "\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "576fb39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2018b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img: np.ndarray, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], resized = (224, 224)) -> torch.Tensor:\n",
    "  \n",
    "  preprocessing = transforms.Compose([\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Resize((224, 224)),\n",
    "                                      transforms.Normalize(mean, std),\n",
    "                                      ])\n",
    "  return preprocessing(img.copy()).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5712fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_img_to_mask(mask_path, bg_path):\n",
    "    \n",
    "    gt_mask = cv2.cvtColor(cv2.imread(mask_path), cv2.COLOR_BGR2GRAY)\n",
    "    gt_bg   = cv2.cvtColor(cv2.imread(bg_path), cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    tumor = (gt_mask == 52).astype(np.uint8).reshape(gt_mask.shape[0], gt_mask.shape[1], 1)\n",
    "    stroma = (gt_mask == 94).astype(np.uint8).reshape(gt_mask.shape[0], gt_mask.shape[1], 1)\n",
    "    normal = (gt_mask == 162).astype(np.uint8).reshape(gt_mask.shape[0], gt_mask.shape[1], 1)\n",
    "    bg = (gt_bg/255).astype(np.uint8).reshape(gt_mask.shape[0], gt_mask.shape[1], 1)\n",
    "    \n",
    "    mask = np.concatenate((tumor, stroma, normal, bg), axis=2)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2b08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slice_bboxes(\n",
    "    image_height: int,\n",
    "    image_width: int,\n",
    "    slice_height: int = 512,\n",
    "    slice_width: int = 512,\n",
    "    overlap_height_ratio: float = 0.2,\n",
    "    overlap_width_ratio: float = 0.2,\n",
    ") -> list[list[int]]:\n",
    "    \"\"\"\n",
    "    Given the height and width of an image, calculates how to divide the image into\n",
    "    overlapping slices according to the height and width provided. These slices are returned\n",
    "    as bounding boxes in xyxy format.\n",
    "\n",
    "    :param image_height: Height of the original image.\n",
    "    :param image_width: Width of the original image.\n",
    "    :param slice_height: Height of each slice\n",
    "    :param slice_width: Width of each slice\n",
    "    :param overlap_height_ratio: Fractional overlap in height of each slice (e.g. an overlap of 0.2 for a slice of size 100 yields an overlap of 20 pixels)\n",
    "    :param overlap_width_ratio: Fractional overlap in width of each slice (e.g. an overlap of 0.2 for a slice of size 100 yields an overlap of 20 pixels)\n",
    "    :return: a list of bounding boxes in xyxy format\n",
    "    \"\"\"\n",
    "\n",
    "    slice_bboxes = []\n",
    "    y_max = y_min = 0\n",
    "    y_overlap = int(overlap_height_ratio * slice_height)\n",
    "    x_overlap = int(overlap_width_ratio * slice_width)\n",
    "    while y_max < image_height:\n",
    "        x_min = x_max = 0\n",
    "        y_max = y_min + slice_height\n",
    "        while x_max < image_width:\n",
    "            x_max = x_min + slice_width\n",
    "            if y_max > image_height or x_max > image_width:\n",
    "                xmax = min(image_width, x_max)\n",
    "                ymax = min(image_height, y_max)\n",
    "                xmin = max(0, xmax - slice_width)\n",
    "                ymin = max(0, ymax - slice_height)\n",
    "                slice_bboxes.append([xmin, ymin, xmax, ymax])\n",
    "            else:\n",
    "                slice_bboxes.append([x_min, y_min, x_max, y_max])\n",
    "            x_min = x_max - x_overlap\n",
    "        y_min = y_max - y_overlap\n",
    "    return slice_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8b9072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_resize(img, mask, factor):\n",
    "    \n",
    "    img_height, img_width, channels = img.shape\n",
    "    \n",
    "    #print(img.shape)\n",
    "    \n",
    "    new_height = int(factor * np.round(img_height/factor))\n",
    "    new_width = int(factor * np.round(img_width/factor))\n",
    "    \n",
    "    img = cv2.resize(img, (max(new_width, 1), max(new_height, 1)))\n",
    "    mask = cv2.resize(mask, (max(new_width, 1), max(new_height, 1)))\n",
    "    \n",
    "    #print(img.shape)\n",
    "    \n",
    "    slice_boxes = calculate_slice_bboxes(new_height, new_width, factor, factor, 0, 0)\n",
    "    \n",
    "    return img, mask, slice_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6575550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mask(img):\n",
    "    \n",
    "    image_tensor = preprocess_image(img,)\n",
    "    \n",
    "    pred_mask = model(image_tensor.to(device))\n",
    "    pred_mask = torch.nn.functional.softmax(pred_mask, dim=1)\n",
    "    pred_mask = np.transpose(pred_mask.squeeze(0).cpu().detach().numpy(), (1, 2, 0))\n",
    "    \n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129e3179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smp.DeepLabV3Plus(encoder_name='resnet50', classes=4, activation=None, encoder_weights=None, ).to(device)\n",
    "model.load_state_dict(torch.load(f='models/deeplabv3plus_dJ_par_resnet50_01.pth', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53af68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6edaf9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_path = 'dataset/2.validation/2.validation/'\n",
    "valid_images = os.listdir('dataset/Dataset/2.validation/2.validation/img/')\n",
    "\n",
    "t_path = 'dataset/Dataset/3.testing/3.testing/'\n",
    "test_images = os.listdir('desktop/Newcastle_University/11_FP_D/Dataset/Dataset/3.testing/3.testing/img/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18005d3",
   "metadata": {},
   "source": [
    "# Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6324367b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_v_0  = []\n",
    "stroma_v_0 = []\n",
    "normal_v_0 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "886061da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in valid_images:\n",
    "    img_path  = v_path + 'img/' + str(i)\n",
    "    mask_path = v_path + 'mask/' + str(i)\n",
    "    bg_path   = v_path + 'background-mask/' + str(i)\n",
    "    \n",
    "    img     = cv2.imread(img_path)\n",
    "    gt_mask = mask_img_to_mask(mask_path, bg_path)\n",
    "    \n",
    "    img, gt_mask, slice_boxes = img_resize(img, gt_mask, 224)\n",
    "    pred = np.zeros(gt_mask.shape)\n",
    "    \n",
    "    for i in slice_boxes:\n",
    "        #print(i)\n",
    "        pred[i[1]:i[3], i[0]:i[2]] = predict_mask(img[i[1]:i[3], i[0]:i[2]])\n",
    "    \n",
    "    pred = pred.round().astype('uint8')\n",
    "    \n",
    "    tumor_v_0.append(jaccard_score(gt_mask[:, :, 0], pred[:, :, 0], average='macro', zero_division=1))\n",
    "    stroma_v_0.append(jaccard_score(gt_mask[:, :, 1], pred[:, :, 1], average='macro', zero_division=1))\n",
    "    normal_v_0.append(jaccard_score(gt_mask[:, :, 2], pred[:, :, 2], average='macro', zero_division=1))\n",
    "    \n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "313886f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5819192156434992\n",
      "0.38623145439061524\n",
      "0.7843028032167065\n",
      "0.5841511577502737\n"
     ]
    }
   ],
   "source": [
    "print('Tumor', np.mean(tumor_v_0))\n",
    "print('Stroma', np.mean(stroma_v_0))\n",
    "print('Normal', np.mean(normal_v_0))\n",
    "print('mIoU', (np.mean(tumor_v_0)+np.mean(stroma_v_0)+np.mean(normal_v_0))/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a648d07",
   "metadata": {},
   "source": [
    "# Validation data with tumor and stroma considered as one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4eedc6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_v_1  = []\n",
    "normal_v_1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "952e5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_images:\n",
    "    img_path  = v_path + 'img/' + str(i)\n",
    "    mask_path = v_path + 'mask/' + str(i)\n",
    "    bg_path   = v_path + 'background-mask/' + str(i)\n",
    "    \n",
    "    img     = cv2.imread(img_path)\n",
    "    gt_mask = mask_img_to_mask(mask_path, bg_path)\n",
    "    \n",
    "    img, gt_mask, slice_boxes = img_resize(img, gt_mask, 224)\n",
    "    pred = np.zeros(gt_mask.shape)\n",
    "    \n",
    "    for i in slice_boxes:\n",
    "        pred[i[1]:i[3], i[0]:i[2]] = predict_mask(img[i[1]:i[3], i[0]:i[2]])\n",
    "    \n",
    "    pred = pred.round().astype('uint8')\n",
    "    \n",
    "    gt_t = (gt_mask[:, :, 0] + gt_mask[:, :, 1])\n",
    "    gt_t[gt_t>1] = 1\n",
    "    pred_t = (pred[:, :, 0] + pred[:, :, 1])\n",
    "    pred_t[pred_t>1] = 1\n",
    "    \n",
    "    tumor_v_1.append(jaccard_score(gt_t, pred_t, average='macro', zero_division=1))\n",
    "    normal_v_1.append(jaccard_score(gt_mask[:, :, 2], pred[:, :, 2], average='macro', zero_division=1))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7292831b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7653811274326422\n",
      "0.7843028032167065\n",
      "0.7748419653246743\n"
     ]
    }
   ],
   "source": [
    "print('Tumor + Stroma', np.mean(tumor_v_1))\n",
    "print('Normal', np.mean(normal_v_1))\n",
    "print('mIoU', (np.mean(tumor_v_1)+np.mean(normal_v_1))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d395b89",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4100a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_v_0  = []\n",
    "stroma_v_0 = []\n",
    "normal_v_0 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b06524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_images:\n",
    "    img_path  = t_path + 'img/' + str(i)\n",
    "    mask_path = t_path + 'mask/' + str(i)\n",
    "    bg_path   = t_path + 'background-mask/' + str(i)\n",
    "    \n",
    "    img     = cv2.imread(img_path)\n",
    "    gt_mask = mask_img_to_mask(mask_path, bg_path)\n",
    "    \n",
    "    img, gt_mask, slice_boxes = img_resize(img, gt_mask, 224)\n",
    "    pred = np.zeros(gt_mask.shape)\n",
    "    \n",
    "    for i in slice_boxes:\n",
    "        pred[i[1]:i[3], i[0]:i[2]] = predict_mask(img[i[1]:i[3], i[0]:i[2]])\n",
    "    \n",
    "    pred = pred.round().astype('uint8')\n",
    "    \n",
    "    tumor_v_0.append(jaccard_score(gt_mask[:, :, 0], pred[:, :, 0], average='macro', zero_division=1))\n",
    "    stroma_v_0.append(jaccard_score(gt_mask[:, :, 1], pred[:, :, 1], average='macro', zero_division=1))\n",
    "    normal_v_0.append(jaccard_score(gt_mask[:, :, 2], pred[:, :, 2], average='macro', zero_division=1))\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b656352d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5276963141296049\n",
      "0.41890617265571883\n",
      "0.9416910281539431\n",
      "0.6294311716464223\n"
     ]
    }
   ],
   "source": [
    "print('Tumor', np.mean(tumor_v_0))\n",
    "print('Stroma', np.mean(stroma_v_0))\n",
    "print('Normal', np.mean(normal_v_0))\n",
    "print('mIoU', (np.mean(tumor_v_0)+np.mean(stroma_v_0)+np.mean(normal_v_0))/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50428c0d",
   "metadata": {},
   "source": [
    "# Test data with tumor and stroma considered as one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "248ad5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_v_1  = []\n",
    "normal_v_1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "954a7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in valid_images:\n",
    "    img_path  = t_path + 'img/' + str(i)\n",
    "    mask_path = t_path + 'mask/' + str(i)\n",
    "    bg_path   = t_path + 'background-mask/' + str(i)\n",
    "    \n",
    "    img     = cv2.imread(img_path)\n",
    "    gt_mask = mask_img_to_mask(mask_path, bg_path)\n",
    "    \n",
    "    img, gt_mask, slice_boxes = img_resize(img, gt_mask, 224)\n",
    "    pred = np.zeros(gt_mask.shape)\n",
    "    \n",
    "    for i in slice_boxes:\n",
    "        pred[i[1]:i[3], i[0]:i[2]] = predict_mask(img[i[1]:i[3], i[0]:i[2]])\n",
    "    \n",
    "    pred = pred.round().astype('uint8')\n",
    "    \n",
    "    gt_t = (gt_mask[:, :, 0] + gt_mask[:, :, 1])\n",
    "    gt_t[gt_t>1] = 1\n",
    "    pred_t = (pred[:, :, 0] + pred[:, :, 1])\n",
    "    pred_t[pred_t>1] = 1\n",
    "    \n",
    "    tumor_v_1.append(jaccard_score(gt_t, pred_t, average='macro', zero_division=1))\n",
    "    normal_v_1.append(jaccard_score(gt_mask[:, :, 2], pred[:, :, 2], average='macro', zero_division=1))\n",
    "    \n",
    "    gc.collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7efd7583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8556801688992536\n",
      "0.9416910281539431\n",
      "0.8986855985265984\n"
     ]
    }
   ],
   "source": [
    "print('Tumor + Stroma', np.mean(tumor_v_1))\n",
    "print('Normal', np.mean(normal_v_1))\n",
    "print('mIoU', (np.mean(tumor_v_1)+np.mean(normal_v_1))/2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "321a108bce31143c0b4654f0e493c95f70da76dcd36cf5d04a19a84c287a7a67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
