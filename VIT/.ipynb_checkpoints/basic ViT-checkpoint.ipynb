{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchsummary\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to edit the csv with correct image_file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_data = pd.read_csv('/home/zephyr/Desktop/Newcastle_University/11_FP_D/Dataset/std_shape/training_1.csv')\n",
    "image_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_data.iloc[0][0][0:74]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_data.iloc[0][0][74:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = '/home/zephyr/Desktop/Newcastle_University/11_FP_D'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(len(image_data)):\n",
    "    image_data.iloc[i][0] = a + image_data.iloc[i][0][74:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image_data.to_csv('/home/zephyr/Desktop/Newcastle_University/11_FP_D/Dataset/std_shape/training_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataframe containing image paths and 1-hot encoded labels\n",
    "image_data = pd.read_csv('/home/zephyr/Desktop/Newcastle_University/11_FP_D/Dataset/std_shape/training_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/zephyr/Desktop/Newcastle_University/11_F...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/zephyr/Desktop/Newcastle_University/11_F...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/zephyr/Desktop/Newcastle_University/11_F...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/zephyr/Desktop/Newcastle_University/11_F...</td>\n",
       "      <td>[0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/zephyr/Desktop/Newcastle_University/11_F...</td>\n",
       "      <td>[0, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_path     labels\n",
       "0  /home/zephyr/Desktop/Newcastle_University/11_F...  [1, 0, 0]\n",
       "1  /home/zephyr/Desktop/Newcastle_University/11_F...  [1, 0, 0]\n",
       "2  /home/zephyr/Desktop/Newcastle_University/11_F...  [1, 0, 0]\n",
       "3  /home/zephyr/Desktop/Newcastle_University/11_F...  [0, 0, 1]\n",
       "4  /home/zephyr/Desktop/Newcastle_University/11_F...  [0, 1, 0]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code to convert labels top proper form (as string to list of integers - 1-hot encoded)\n",
    "list(map(int, image_data.iloc[700][1].strip('][').split(', ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(image_data, test_size=0.2, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3754"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('vit_base_patch32_224', pretrained = False, num_classes = 3)\n",
    "#print(model(torch.randn(1, 3, 224, 224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 768, 7, 7]       2,360,064\n",
      "          Identity-2              [-1, 49, 768]               0\n",
      "        PatchEmbed-3              [-1, 49, 768]               0\n",
      "           Dropout-4              [-1, 50, 768]               0\n",
      "         LayerNorm-5              [-1, 50, 768]           1,536\n",
      "            Linear-6             [-1, 50, 2304]       1,771,776\n",
      "           Dropout-7           [-1, 12, 50, 50]               0\n",
      "            Linear-8              [-1, 50, 768]         590,592\n",
      "           Dropout-9              [-1, 50, 768]               0\n",
      "        Attention-10              [-1, 50, 768]               0\n",
      "         Identity-11              [-1, 50, 768]               0\n",
      "        LayerNorm-12              [-1, 50, 768]           1,536\n",
      "           Linear-13             [-1, 50, 3072]       2,362,368\n",
      "             GELU-14             [-1, 50, 3072]               0\n",
      "          Dropout-15             [-1, 50, 3072]               0\n",
      "           Linear-16              [-1, 50, 768]       2,360,064\n",
      "          Dropout-17              [-1, 50, 768]               0\n",
      "              Mlp-18              [-1, 50, 768]               0\n",
      "         Identity-19              [-1, 50, 768]               0\n",
      "            Block-20              [-1, 50, 768]               0\n",
      "        LayerNorm-21              [-1, 50, 768]           1,536\n",
      "           Linear-22             [-1, 50, 2304]       1,771,776\n",
      "          Dropout-23           [-1, 12, 50, 50]               0\n",
      "           Linear-24              [-1, 50, 768]         590,592\n",
      "          Dropout-25              [-1, 50, 768]               0\n",
      "        Attention-26              [-1, 50, 768]               0\n",
      "         Identity-27              [-1, 50, 768]               0\n",
      "        LayerNorm-28              [-1, 50, 768]           1,536\n",
      "           Linear-29             [-1, 50, 3072]       2,362,368\n",
      "             GELU-30             [-1, 50, 3072]               0\n",
      "          Dropout-31             [-1, 50, 3072]               0\n",
      "           Linear-32              [-1, 50, 768]       2,360,064\n",
      "          Dropout-33              [-1, 50, 768]               0\n",
      "              Mlp-34              [-1, 50, 768]               0\n",
      "         Identity-35              [-1, 50, 768]               0\n",
      "            Block-36              [-1, 50, 768]               0\n",
      "        LayerNorm-37              [-1, 50, 768]           1,536\n",
      "           Linear-38             [-1, 50, 2304]       1,771,776\n",
      "          Dropout-39           [-1, 12, 50, 50]               0\n",
      "           Linear-40              [-1, 50, 768]         590,592\n",
      "          Dropout-41              [-1, 50, 768]               0\n",
      "        Attention-42              [-1, 50, 768]               0\n",
      "         Identity-43              [-1, 50, 768]               0\n",
      "        LayerNorm-44              [-1, 50, 768]           1,536\n",
      "           Linear-45             [-1, 50, 3072]       2,362,368\n",
      "             GELU-46             [-1, 50, 3072]               0\n",
      "          Dropout-47             [-1, 50, 3072]               0\n",
      "           Linear-48              [-1, 50, 768]       2,360,064\n",
      "          Dropout-49              [-1, 50, 768]               0\n",
      "              Mlp-50              [-1, 50, 768]               0\n",
      "         Identity-51              [-1, 50, 768]               0\n",
      "            Block-52              [-1, 50, 768]               0\n",
      "        LayerNorm-53              [-1, 50, 768]           1,536\n",
      "           Linear-54             [-1, 50, 2304]       1,771,776\n",
      "          Dropout-55           [-1, 12, 50, 50]               0\n",
      "           Linear-56              [-1, 50, 768]         590,592\n",
      "          Dropout-57              [-1, 50, 768]               0\n",
      "        Attention-58              [-1, 50, 768]               0\n",
      "         Identity-59              [-1, 50, 768]               0\n",
      "        LayerNorm-60              [-1, 50, 768]           1,536\n",
      "           Linear-61             [-1, 50, 3072]       2,362,368\n",
      "             GELU-62             [-1, 50, 3072]               0\n",
      "          Dropout-63             [-1, 50, 3072]               0\n",
      "           Linear-64              [-1, 50, 768]       2,360,064\n",
      "          Dropout-65              [-1, 50, 768]               0\n",
      "              Mlp-66              [-1, 50, 768]               0\n",
      "         Identity-67              [-1, 50, 768]               0\n",
      "            Block-68              [-1, 50, 768]               0\n",
      "        LayerNorm-69              [-1, 50, 768]           1,536\n",
      "           Linear-70             [-1, 50, 2304]       1,771,776\n",
      "          Dropout-71           [-1, 12, 50, 50]               0\n",
      "           Linear-72              [-1, 50, 768]         590,592\n",
      "          Dropout-73              [-1, 50, 768]               0\n",
      "        Attention-74              [-1, 50, 768]               0\n",
      "         Identity-75              [-1, 50, 768]               0\n",
      "        LayerNorm-76              [-1, 50, 768]           1,536\n",
      "           Linear-77             [-1, 50, 3072]       2,362,368\n",
      "             GELU-78             [-1, 50, 3072]               0\n",
      "          Dropout-79             [-1, 50, 3072]               0\n",
      "           Linear-80              [-1, 50, 768]       2,360,064\n",
      "          Dropout-81              [-1, 50, 768]               0\n",
      "              Mlp-82              [-1, 50, 768]               0\n",
      "         Identity-83              [-1, 50, 768]               0\n",
      "            Block-84              [-1, 50, 768]               0\n",
      "        LayerNorm-85              [-1, 50, 768]           1,536\n",
      "           Linear-86             [-1, 50, 2304]       1,771,776\n",
      "          Dropout-87           [-1, 12, 50, 50]               0\n",
      "           Linear-88              [-1, 50, 768]         590,592\n",
      "          Dropout-89              [-1, 50, 768]               0\n",
      "        Attention-90              [-1, 50, 768]               0\n",
      "         Identity-91              [-1, 50, 768]               0\n",
      "        LayerNorm-92              [-1, 50, 768]           1,536\n",
      "           Linear-93             [-1, 50, 3072]       2,362,368\n",
      "             GELU-94             [-1, 50, 3072]               0\n",
      "          Dropout-95             [-1, 50, 3072]               0\n",
      "           Linear-96              [-1, 50, 768]       2,360,064\n",
      "          Dropout-97              [-1, 50, 768]               0\n",
      "              Mlp-98              [-1, 50, 768]               0\n",
      "         Identity-99              [-1, 50, 768]               0\n",
      "           Block-100              [-1, 50, 768]               0\n",
      "       LayerNorm-101              [-1, 50, 768]           1,536\n",
      "          Linear-102             [-1, 50, 2304]       1,771,776\n",
      "         Dropout-103           [-1, 12, 50, 50]               0\n",
      "          Linear-104              [-1, 50, 768]         590,592\n",
      "         Dropout-105              [-1, 50, 768]               0\n",
      "       Attention-106              [-1, 50, 768]               0\n",
      "        Identity-107              [-1, 50, 768]               0\n",
      "       LayerNorm-108              [-1, 50, 768]           1,536\n",
      "          Linear-109             [-1, 50, 3072]       2,362,368\n",
      "            GELU-110             [-1, 50, 3072]               0\n",
      "         Dropout-111             [-1, 50, 3072]               0\n",
      "          Linear-112              [-1, 50, 768]       2,360,064\n",
      "         Dropout-113              [-1, 50, 768]               0\n",
      "             Mlp-114              [-1, 50, 768]               0\n",
      "        Identity-115              [-1, 50, 768]               0\n",
      "           Block-116              [-1, 50, 768]               0\n",
      "       LayerNorm-117              [-1, 50, 768]           1,536\n",
      "          Linear-118             [-1, 50, 2304]       1,771,776\n",
      "         Dropout-119           [-1, 12, 50, 50]               0\n",
      "          Linear-120              [-1, 50, 768]         590,592\n",
      "         Dropout-121              [-1, 50, 768]               0\n",
      "       Attention-122              [-1, 50, 768]               0\n",
      "        Identity-123              [-1, 50, 768]               0\n",
      "       LayerNorm-124              [-1, 50, 768]           1,536\n",
      "          Linear-125             [-1, 50, 3072]       2,362,368\n",
      "            GELU-126             [-1, 50, 3072]               0\n",
      "         Dropout-127             [-1, 50, 3072]               0\n",
      "          Linear-128              [-1, 50, 768]       2,360,064\n",
      "         Dropout-129              [-1, 50, 768]               0\n",
      "             Mlp-130              [-1, 50, 768]               0\n",
      "        Identity-131              [-1, 50, 768]               0\n",
      "           Block-132              [-1, 50, 768]               0\n",
      "       LayerNorm-133              [-1, 50, 768]           1,536\n",
      "          Linear-134             [-1, 50, 2304]       1,771,776\n",
      "         Dropout-135           [-1, 12, 50, 50]               0\n",
      "          Linear-136              [-1, 50, 768]         590,592\n",
      "         Dropout-137              [-1, 50, 768]               0\n",
      "       Attention-138              [-1, 50, 768]               0\n",
      "        Identity-139              [-1, 50, 768]               0\n",
      "       LayerNorm-140              [-1, 50, 768]           1,536\n",
      "          Linear-141             [-1, 50, 3072]       2,362,368\n",
      "            GELU-142             [-1, 50, 3072]               0\n",
      "         Dropout-143             [-1, 50, 3072]               0\n",
      "          Linear-144              [-1, 50, 768]       2,360,064\n",
      "         Dropout-145              [-1, 50, 768]               0\n",
      "             Mlp-146              [-1, 50, 768]               0\n",
      "        Identity-147              [-1, 50, 768]               0\n",
      "           Block-148              [-1, 50, 768]               0\n",
      "       LayerNorm-149              [-1, 50, 768]           1,536\n",
      "          Linear-150             [-1, 50, 2304]       1,771,776\n",
      "         Dropout-151           [-1, 12, 50, 50]               0\n",
      "          Linear-152              [-1, 50, 768]         590,592\n",
      "         Dropout-153              [-1, 50, 768]               0\n",
      "       Attention-154              [-1, 50, 768]               0\n",
      "        Identity-155              [-1, 50, 768]               0\n",
      "       LayerNorm-156              [-1, 50, 768]           1,536\n",
      "          Linear-157             [-1, 50, 3072]       2,362,368\n",
      "            GELU-158             [-1, 50, 3072]               0\n",
      "         Dropout-159             [-1, 50, 3072]               0\n",
      "          Linear-160              [-1, 50, 768]       2,360,064\n",
      "         Dropout-161              [-1, 50, 768]               0\n",
      "             Mlp-162              [-1, 50, 768]               0\n",
      "        Identity-163              [-1, 50, 768]               0\n",
      "           Block-164              [-1, 50, 768]               0\n",
      "       LayerNorm-165              [-1, 50, 768]           1,536\n",
      "          Linear-166             [-1, 50, 2304]       1,771,776\n",
      "         Dropout-167           [-1, 12, 50, 50]               0\n",
      "          Linear-168              [-1, 50, 768]         590,592\n",
      "         Dropout-169              [-1, 50, 768]               0\n",
      "       Attention-170              [-1, 50, 768]               0\n",
      "        Identity-171              [-1, 50, 768]               0\n",
      "       LayerNorm-172              [-1, 50, 768]           1,536\n",
      "          Linear-173             [-1, 50, 3072]       2,362,368\n",
      "            GELU-174             [-1, 50, 3072]               0\n",
      "         Dropout-175             [-1, 50, 3072]               0\n",
      "          Linear-176              [-1, 50, 768]       2,360,064\n",
      "         Dropout-177              [-1, 50, 768]               0\n",
      "             Mlp-178              [-1, 50, 768]               0\n",
      "        Identity-179              [-1, 50, 768]               0\n",
      "           Block-180              [-1, 50, 768]               0\n",
      "       LayerNorm-181              [-1, 50, 768]           1,536\n",
      "          Linear-182             [-1, 50, 2304]       1,771,776\n",
      "         Dropout-183           [-1, 12, 50, 50]               0\n",
      "          Linear-184              [-1, 50, 768]         590,592\n",
      "         Dropout-185              [-1, 50, 768]               0\n",
      "       Attention-186              [-1, 50, 768]               0\n",
      "        Identity-187              [-1, 50, 768]               0\n",
      "       LayerNorm-188              [-1, 50, 768]           1,536\n",
      "          Linear-189             [-1, 50, 3072]       2,362,368\n",
      "            GELU-190             [-1, 50, 3072]               0\n",
      "         Dropout-191             [-1, 50, 3072]               0\n",
      "          Linear-192              [-1, 50, 768]       2,360,064\n",
      "         Dropout-193              [-1, 50, 768]               0\n",
      "             Mlp-194              [-1, 50, 768]               0\n",
      "        Identity-195              [-1, 50, 768]               0\n",
      "           Block-196              [-1, 50, 768]               0\n",
      "       LayerNorm-197              [-1, 50, 768]           1,536\n",
      "        Identity-198                  [-1, 768]               0\n",
      "          Linear-199                    [-1, 3]           2,307\n",
      "================================================================\n",
      "Total params: 87,418,371\n",
      "Trainable params: 87,418,371\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 95.61\n",
      "Params size (MB): 333.47\n",
      "Estimated Total Size (MB): 429.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torchsummary.summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_p = '/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/436219-7159-48057-[1, 0, 0].png'\n",
    "img = cv2.imread(im_p)\n",
    "img = transforms.ToTensor()(img)\n",
    "#img = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-21 13:41:16.922933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zephyr/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-06-21 13:41:16.922997: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('runs/vit_base_patch32_224_structure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image('histo', img)\n",
    "\n",
    "#!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zephyr/.local/lib/python3.10/site-packages/torch/__init__.py:772: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "/home/zephyr/.local/lib/python3.10/site-packages/timm/models/vision_transformer.py:202: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "writer.add_graph(model, img.unsqueeze(0))\n",
    "\n",
    "#tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
