{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-TjxDf9nCvao"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n","\n","import timm\n","import torch\n","import torchvision\n","import torchsummary\n","from torch import nn\n","from torch.optim import Adam\n","from torchvision import transforms, utils\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qcb81xk1Cvar"},"outputs":[],"source":["os.chdir(f'./Transformer_Explainability')\n","from Transformer_Explainability.baselines.ViT.ViT_LRP import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ES5brQVHCvas","outputId":"2bda39dc-f892-4458-ded9-7619a4fde143"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/Transformer_Explainability\n"]}],"source":["print(os.getcwd())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLFTtLOuCvat"},"outputs":[],"source":["model = VisionTransformer(patch_size=32, embed_dim=768, depth=12, num_heads=12, mlp_ratio=4, qkv_bias=True, num_classes=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_3ZEuFbMCvat","outputId":"fddab2d0-9cf9-4525-e1c8-9a7415eb70d9"},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'size'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/vit_with_explainability.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/vit_with_explainability.ipynb#ch0000004?line=0'>1</a>\u001b[0m torchsummary\u001b[39m.\u001b[39;49msummary(model, (\u001b[39m3\u001b[39;49m, \u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m))\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchsummary/torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[1;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/Desktop/Newcastle_University/11_FP_D/code/Transformer_Explainability/baselines/ViT/ViT_LRP.py:311\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    309\u001b[0m cls_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls_token\u001b[39m.\u001b[39mexpand(B, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# stole cls_tokens impl from Phil Wang, thanks\u001b[39;00m\n\u001b[1;32m    310\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((cls_tokens, x), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 311\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd([x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_embed])\n\u001b[1;32m    313\u001b[0m x\u001b[39m.\u001b[39mregister_hook(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_inp_grad)\n\u001b[1;32m    315\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1130\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m-> 1131\u001b[0m         hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, \u001b[39minput\u001b[39;49m, result)\n\u001b[1;32m   1132\u001b[0m         \u001b[39mif\u001b[39;00m hook_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             result \u001b[39m=\u001b[39m hook_result\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchsummary/torchsummary.py:19\u001b[0m, in \u001b[0;36msummary.<locals>.register_hook.<locals>.hook\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     17\u001b[0m m_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (class_name, module_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m summary[m_key] \u001b[39m=\u001b[39m OrderedDict()\n\u001b[0;32m---> 19\u001b[0m summary[m_key][\u001b[39m\"\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39minput\u001b[39;49m[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msize())\n\u001b[1;32m     20\u001b[0m summary[m_key][\u001b[39m\"\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m batch_size\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"]}],"source":["torchsummary.summary(model, (3, 224, 224))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"71it9N8LCvat","outputId":"1378281c-3a5a-4cbe-b4f8-6fd7ac88e9c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["VisionTransformer(\n","  (patch_embed): PatchEmbed(\n","    (proj): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32))\n","  )\n","  (blocks): ModuleList(\n","    (0): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (1): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (2): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (3): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (4): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (5): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (6): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (7): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (8): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (9): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (10): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","    (11): Block(\n","      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (matmul1): einsum()\n","        (matmul2): einsum()\n","        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=768, out_features=768, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","        (softmax): Softmax(dim=-1)\n","      )\n","      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","        (act): GELU()\n","        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (add1): Add()\n","      (add2): Add()\n","      (clone1): Clone()\n","      (clone2): Clone()\n","    )\n","  )\n","  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  (head): Linear(in_features=768, out_features=3, bias=True)\n","  (pool): IndexSelect()\n","  (add): Add()\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_C4UhIdUCvau"},"outputs":[],"source":["im_p = '/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/436219-7159-48057-[1, 0, 0].png'\n","img = cv2.imread(im_p)\n","img = transforms.ToTensor()(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XW41kIMWCvau","outputId":"8382b084-9263-4867-c336-b54c60e6de62"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-06-21 19:10:13.564949: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/zephyr/.local/lib/python3.10/site-packages/cv2/../../lib64:\n","2022-06-21 19:10:13.564983: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"]}],"source":["writer = SummaryWriter('/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/runs/vit_exp_patch32_224_structure')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rk_eScB0Cvau","outputId":"aec1ddf4-7a1b-4577-fedb-d052a9bc7fda"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/Transformer_Explainability/baselines/ViT/ViT_LRP.py:233: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n","  assert H == self.img_size[0] and W == self.img_size[1], \\\n"]},{"ename":"AttributeError","evalue":"'list' object has no attribute 'size'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/vit_with_explainability.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/vit_with_explainability.ipynb#ch0000007?line=0'>1</a>\u001b[0m writer\u001b[39m.\u001b[39;49madd_graph(model, img\u001b[39m.\u001b[39;49munsqueeze(\u001b[39m0\u001b[39;49m))\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/tensorboard/writer.py:736\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    733\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_once(\u001b[39m\"\u001b[39m\u001b[39mtensorboard.logging.add_graph\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    734\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    735\u001b[0m     \u001b[39m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_file_writer()\u001b[39m.\u001b[39madd_graph(graph(model, input_to_model, verbose, use_strict_trace))\n\u001b[1;32m    737\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    738\u001b[0m     \u001b[39m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m caffe2_pb2\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/tensorboard/_pytorch_graph.py:291\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mselect_model_mode_for_export(model, torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mTrainingMode\u001b[39m.\u001b[39mEVAL):  \u001b[39m# TODO: move outside of torch.onnx?\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m         trace \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, args, strict\u001b[39m=\u001b[39;49muse_strict_trace)\n\u001b[1;32m    292\u001b[0m         graph \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mgraph\n\u001b[1;32m    293\u001b[0m         torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_jit_pass_inline(graph)\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_trace.py:741\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[39mreturn\u001b[39;00m func\n\u001b[1;32m    740\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m--> 741\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    742\u001b[0m         func,\n\u001b[1;32m    743\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[1;32m    744\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    745\u001b[0m         check_trace,\n\u001b[1;32m    746\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[1;32m    747\u001b[0m         check_tolerance,\n\u001b[1;32m    748\u001b[0m         strict,\n\u001b[1;32m    749\u001b[0m         _force_outplace,\n\u001b[1;32m    750\u001b[0m         _module_class,\n\u001b[1;32m    751\u001b[0m     )\n\u001b[1;32m    753\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    754\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    755\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[1;32m    756\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    757\u001b[0m ):\n\u001b[1;32m    758\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    759\u001b[0m         func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    760\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m         _module_class,\n\u001b[1;32m    768\u001b[0m     )\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/jit/_trace.py:958\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    954\u001b[0m     argument_names \u001b[39m=\u001b[39m get_callable_argument_names(func)\n\u001b[1;32m    956\u001b[0m example_inputs \u001b[39m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m--> 958\u001b[0m module\u001b[39m.\u001b[39;49m_c\u001b[39m.\u001b[39;49m_create_method_from_trace(\n\u001b[1;32m    959\u001b[0m     method_name,\n\u001b[1;32m    960\u001b[0m     func,\n\u001b[1;32m    961\u001b[0m     example_inputs,\n\u001b[1;32m    962\u001b[0m     var_lookup_fn,\n\u001b[1;32m    963\u001b[0m     strict,\n\u001b[1;32m    964\u001b[0m     _force_outplace,\n\u001b[1;32m    965\u001b[0m     argument_names,\n\u001b[1;32m    966\u001b[0m )\n\u001b[1;32m    967\u001b[0m check_trace_method \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_c\u001b[39m.\u001b[39m_get_method(method_name)\n\u001b[1;32m    969\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1098\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1099\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n","File \u001b[0;32m~/Desktop/Newcastle_University/11_FP_D/code/Transformer_Explainability/baselines/ViT/ViT_LRP.py:311\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    309\u001b[0m cls_tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls_token\u001b[39m.\u001b[39mexpand(B, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# stole cls_tokens impl from Phil Wang, thanks\u001b[39;00m\n\u001b[1;32m    310\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((cls_tokens, x), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 311\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd([x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpos_embed])\n\u001b[1;32m    313\u001b[0m x\u001b[39m.\u001b[39mregister_hook(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_inp_grad)\n\u001b[1;32m    315\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1131\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1130\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[0;32m-> 1131\u001b[0m         hook_result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39;49m, \u001b[39minput\u001b[39;49m, result)\n\u001b[1;32m   1132\u001b[0m         \u001b[39mif\u001b[39;00m hook_result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m             result \u001b[39m=\u001b[39m hook_result\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchsummary/torchsummary.py:19\u001b[0m, in \u001b[0;36msummary.<locals>.register_hook.<locals>.hook\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     17\u001b[0m m_key \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (class_name, module_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m     18\u001b[0m summary[m_key] \u001b[39m=\u001b[39m OrderedDict()\n\u001b[0;32m---> 19\u001b[0m summary[m_key][\u001b[39m\"\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39minput\u001b[39;49m[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msize())\n\u001b[1;32m     20\u001b[0m summary[m_key][\u001b[39m\"\u001b[39m\u001b[39minput_shape\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m batch_size\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(output, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"]}],"source":["writer.add_graph(model, img.unsqueeze(0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTpynvKKCvav"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bY9FiF7DCvav"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iTplCvdTCvav"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gtWKvYu-Cvaw"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"urYUS20uCvaw"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PO8gqJzPCvaw"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ShmZSTv2Cvaw"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8QBb87GSCvaw"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n1pNXV2zCvaw"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"colab":{"name":"vit_with_explainability.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}