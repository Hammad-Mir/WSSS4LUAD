{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9cf3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\".\")\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "\n",
    "from wetr.PAR import PAR\n",
    "from datasets import coco\n",
    "from utils import evaluate, imutils\n",
    "from wetr.model_attn_aff import WeTr\n",
    "from utils.losses import get_aff_loss\n",
    "from utils.optimizer import PolyWarmupAdamW\n",
    "from utils.AverageMeter import AverageMeter\n",
    "from utils.camutils import (cam_to_label, cams_to_affinity_label, ignore_img_box,\n",
    "                            multi_scale_cam, multi_scale_cam_with_aff_mat,\n",
    "                            propagte_aff_cam_with_bkg, refine_cams_with_bkg_v2,\n",
    "                            refine_cams_with_cls_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fae2eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/zephyr/Desktop/Newcastle_University/11_FP_D/code/AFA/afa'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c246c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858c789e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--backend'], dest='backend', nargs=None, const=None, default='nccl', type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--config\",\n",
    "                    default='configs/coco_attn_reg.yaml',\n",
    "                    type=str,\n",
    "                    help=\"config\")\n",
    "parser.add_argument(\"--pooling\", default=\"gmp\", type=str, help=\"pooling method\")\n",
    "parser.add_argument(\"--seg_detach\", action=\"store_true\", help=\"detach seg\")\n",
    "parser.add_argument(\"--work_dir\", default=None, type=str, help=\"work_dir\")\n",
    "parser.add_argument(\"--local_rank\", default=-1, type=int, help=\"local_rank\")\n",
    "parser.add_argument(\"--radius\", default=8, type=int, help=\"radius\")\n",
    "parser.add_argument(\"--crop_size\", default=224, type=int, help=\"crop_size\")\n",
    "parser.add_argument('--backend', default='nccl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deffffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac70a73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_down_size(ori_shape=(224,224), stride=16):\n",
    "    h, w = ori_shape\n",
    "    _h = h // stride + 1 - ((h % stride) == 0)\n",
    "    _w = w // stride + 1 - ((w % stride) == 0)\n",
    "    return _h, _w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "769b26f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.set_device(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0cb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = coco.CocoClsDataset(\n",
    "    root_dir=cfg.dataset.root_dir,\n",
    "    name_list_dir=cfg.dataset.name_list_dir,\n",
    "    split=cfg.train.split,\n",
    "    stage='train',\n",
    "    aug=True,\n",
    "    resize_range=cfg.dataset.resize_range,\n",
    "    rescale_range=cfg.dataset.rescale_range,\n",
    "    crop_size=cfg.dataset.crop_size,\n",
    "    img_fliplr=True,\n",
    "    ignore_index=cfg.dataset.ignore_index,\n",
    "    num_classes=cfg.dataset.num_classes,\n",
    "    )\n",
    "    \n",
    "val_dataset = coco.CocoSegDataset(\n",
    "    root_dir=cfg.dataset.root_dir,\n",
    "    name_list_dir=cfg.dataset.name_list_dir,\n",
    "    split=cfg.val.split,\n",
    "    stage='val',\n",
    "    aug=False,\n",
    "    ignore_index=cfg.dataset.ignore_index,\n",
    "    num_classes=cfg.dataset.num_classes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e1816",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = DistributedSampler(train_dataset,shuffle=True)\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=cfg.train.samples_per_gpu,\n",
    "                          #shuffle=True,\n",
    "                          num_workers=num_workers,\n",
    "                          pin_memory=False,\n",
    "                          drop_last=True,\n",
    "                          sampler=train_sampler,\n",
    "                          prefetch_factor=4)\n",
    "\n",
    "val_loader = DataLoader(val_dataset,\n",
    "                        batch_size=1,\n",
    "                        shuffle=False,\n",
    "                        num_workers=num_workers,\n",
    "                        pin_memory=False,\n",
    "                        drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df76bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(args.local_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b8fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.init_process_group(backend='nccl',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9690bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PAR()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wetr = WeTr(backbone='mit_b1',\n",
    "            stride=[4, 2, 2, 1],\n",
    "            num_classes=3,\n",
    "            embedding_dim=256,\n",
    "            pretrained=False,\n",
    "            pooling='gmp',\n",
    "           )\n",
    "\n",
    "param_groups = wetr.get_param_groups()\n",
    "par = PAR(num_iter=15, dilations=[1,2,4,8,12,24])\n",
    "\n",
    "wetr.to(device)\n",
    "par.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62b7ba20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "SyncBatchNorm expected input tensor to be on GPU",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwetr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcam_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Newcastle_University/11_FP_D/code/AFA/afa/wetr/model_attn_aff.py:70\u001b[0m, in \u001b[0;36mWeTr.forward\u001b[0;34m(self, x, cam_only, seg_detach)\u001b[0m\n\u001b[1;32m     67\u001b[0m _x, _attns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m     68\u001b[0m _x1, _x2, _x3, _x4 \u001b[38;5;241m=\u001b[39m _x\n\u001b[0;32m---> 70\u001b[0m seg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m#seg = self.decoder(_x4)\u001b[39;00m\n\u001b[1;32m     73\u001b[0m attn_cat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(_attns[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;66;03m#.detach()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Newcastle_University/11_FP_D/code/AFA/afa/wetr/segformer_head.py:76\u001b[0m, in \u001b[0;36mSegFormerHead.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     72\u001b[0m _c2 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(_c2, size\u001b[38;5;241m=\u001b[39mc1\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m:],mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m,align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m _c1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_c1(c1)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(n, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, c1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m], c1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m---> 76\u001b[0m logit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear_fuse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_c4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_c3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_c2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_c1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(logit)\n\u001b[1;32m     79\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_pred(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mmcv/cnn/bricks/conv_module.py:209\u001b[0m, in \u001b[0;36mConvModule.forward\u001b[0;34m(self, x, activate, norm)\u001b[0m\n\u001b[1;32m    207\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m norm \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_norm:\n\u001b[0;32m--> 209\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mact\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m activate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_activation:\n\u001b[1;32m    211\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/batchnorm.py:682\u001b[0m, in \u001b[0;36mSyncBatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;66;03m# currently only GPU input is supported\u001b[39;00m\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mis_cuda:\n\u001b[0;32m--> 682\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSyncBatchNorm expected input tensor to be on GPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input_dim(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_non_zero_input_channels(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: SyncBatchNorm expected input tensor to be on GPU"
     ]
    }
   ],
   "source": [
    "wetr(torch.randn(1, 3, 224, 224), cam_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a1958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17498f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101c7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    num_workers = 10\n",
    "\n",
    "    mask_size = int(cfg.dataset.crop_size // 16)\n",
    "    infer_size = int((224 * max([1, 0.5, 1.5])) // 16)\n",
    "    attn_mask = get_mask_by_radius(h=mask_size, w=mask_size, radius=args.radius)\n",
    "    attn_mask_infer = get_mask_by_radius(h=infer_size, w=infer_size, radius=args.radius)\n",
    "    \n",
    "    optimizer = PolyWarmupAdamW(\n",
    "        params=[\n",
    "            {\n",
    "                \"params\": param_groups[0],\n",
    "                \"lr\": 6e-5,\n",
    "                \"weight_decay\": 0.01,\n",
    "            },\n",
    "            {\n",
    "                \"params\": param_groups[1],\n",
    "                \"lr\": 0.0, ## freeze norm layers\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "            {\n",
    "                \"params\": param_groups[2],\n",
    "                \"lr\": 6e-5*10,\n",
    "                \"weight_decay\": 0.01,\n",
    "            },\n",
    "            {\n",
    "                \"params\": param_groups[3],\n",
    "                \"lr\": 6e-5*10,\n",
    "                \"weight_decay\": 0.01,\n",
    "            },\n",
    "        ],\n",
    "        lr = 6e-5,\n",
    "        weight_decay = 0.01,\n",
    "        betas = [0.9, 0.999],\n",
    "        warmup_iter = 1500,\n",
    "        max_iter = 80000,\n",
    "        warmup_ratio = 1e-6,\n",
    "        power = 1.0\n",
    "    )\n",
    "    \n",
    "    #wetr = DistributedDataParallel(wetr, device_ids=[args.local_rank], find_unused_parameters=True)\n",
    "    # loss_layer = DenseEnergyLoss(weight=1e-7, sigma_rgb=15, sigma_xy=100, scale_factor=0.5)\n",
    "    train_sampler.set_epoch(np.random.randint(80000))\n",
    "    train_loader_iter = iter(train_loader)\n",
    "\n",
    "    #for n_iter in tqdm(range(cfg.train.max_iters), total=cfg.train.max_iters, dynamic_ncols=True):\n",
    "    avg_meter = AverageMeter()\n",
    "\n",
    "    bkg_cls = torch.ones(size=(2, 1))\n",
    "    \n",
    "    img_box - None\n",
    "\n",
    "    for n_iter in range(80000):\n",
    "        \n",
    "        try:\n",
    "            #img_name, inputs, cls_labels, img_box = next(train_loader_iter)\n",
    "            inputs, cls_labels = next(train_loader_iter)\n",
    "        except:\n",
    "            train_sampler.set_epoch(np.random.randint(80000))\n",
    "            train_loader_iter = iter(train_loader)\n",
    "            img_name, inputs, cls_labels, img_box = next(train_loader_iter)\n",
    "        \n",
    "        inputs = inputs.to(device, non_blocking=True)\n",
    "        inputs_denorm = imutils.denormalize_img2(inputs.clone())\n",
    "        cls_labels = cls_labels.to(device, non_blocking=True)\n",
    "        \n",
    "        cls, segs, attns, attn_pred = wetr(inputs, seg_detach=args.seg_detach)\n",
    "\n",
    "        cams, aff_mat = multi_scale_cam_with_aff_mat(wetr, inputs=inputs, scales=cfg.cam.scales)\n",
    "        valid_cam, pseudo_label = cam_to_label(cams.detach(), cls_label=cls_labels, img_box=img_box, ignore_mid=True, cfg=cfg)\n",
    "\n",
    "        ######################\n",
    "        valid_cam_resized = F.interpolate(valid_cam, size=(infer_size, infer_size), mode='bilinear', align_corners=False)\n",
    "\n",
    "        aff_cam_l = propagte_aff_cam_with_bkg(valid_cam_resized, aff=aff_mat.detach().clone(), mask=attn_mask_infer, cls_labels=cls_labels, bkg_score=cfg.cam.low_thre)\n",
    "        aff_cam_l = F.interpolate(aff_cam_l, size=pseudo_label.shape[1:], mode='bilinear', align_corners=False)\n",
    "        aff_cam_h = propagte_aff_cam_with_bkg(valid_cam_resized, aff=aff_mat.detach().clone(), mask=attn_mask_infer, cls_labels=cls_labels, bkg_score=cfg.cam.high_thre)\n",
    "        aff_cam_h = F.interpolate(aff_cam_h, size=pseudo_label.shape[1:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        \n",
    "        bkg_cls = bkg_cls.to(cams.device)\n",
    "        _cls_labels = torch.cat((bkg_cls, cls_labels), dim=1)\n",
    "\n",
    "        refined_aff_cam_l = refine_cams_with_cls_label(par, inputs_denorm, cams=aff_cam_l, labels=_cls_labels, img_box=img_box)\n",
    "        refined_aff_label_l = refined_aff_cam_l.argmax(dim=1)\n",
    "        refined_aff_cam_h = refine_cams_with_cls_label(par, inputs_denorm, cams=aff_cam_h, labels=_cls_labels, img_box=img_box)\n",
    "        refined_aff_label_h = refined_aff_cam_h.argmax(dim=1)\n",
    "\n",
    "        aff_cam = aff_cam_l[:,1:]\n",
    "        refined_aff_cam = refined_aff_cam_l[:,1:,]\n",
    "        refined_aff_label = refined_aff_label_h.clone()\n",
    "        refined_aff_label[refined_aff_label_h == 0] = cfg.dataset.ignore_index\n",
    "        refined_aff_label[(refined_aff_label_h + refined_aff_label_l) == 0] = 0\n",
    "        refined_aff_label = ignore_img_box(refined_aff_label, img_box=img_box, ignore_index=cfg.dataset.ignore_index)\n",
    "        ######################\n",
    "\n",
    "        refined_pseudo_label = refine_cams_with_bkg_v2(par, inputs_denorm, cams=cams, cls_labels=cls_labels, cfg=cfg, img_box=img_box)\n",
    "\n",
    "        if n_iter <= 15000:\n",
    "            refined_aff_label = refined_pseudo_label\n",
    "\n",
    "        aff_label = cams_to_affinity_label(refined_aff_label, mask=attn_mask, ignore_index=cfg.dataset.ignore_index)\n",
    "        aff_loss, pos_count, neg_count = get_aff_loss(attn_pred, aff_label)\n",
    "\n",
    "        segs = F.interpolate(segs, size=refined_pseudo_label.shape[1:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        seg_loss = get_seg_loss(segs, refined_aff_label.type(torch.long), ignore_index=cfg.dataset.ignore_index)\n",
    "        #reg_loss = get_energy_loss(img=inputs, logit=segs, label=refined_aff_label, img_box=img_box, loss_layer=loss_layer)\n",
    "        #seg_loss = F.cross_entropy(segs, pseudo_label.type(torch.long), ignore_index=cfg.dataset.ignore_index)\n",
    "        cls_loss = F.multilabel_soft_margin_loss(cls, cls_labels)\n",
    "        \n",
    "        if n_iter <= cfg.train.cam_iters:\n",
    "            loss = 1.0 * cls_loss + 0.0 * seg_loss + 0.0 * aff_loss# + 0.0 * reg_loss\n",
    "        else: \n",
    "            loss = 1.0 * cls_loss + 0.1 * seg_loss + 0.1 * aff_loss# + 0.01 * reg_loss\n",
    "\n",
    "\n",
    "        avg_meter.add({'cls_loss': cls_loss.item(), 'seg_loss': seg_loss.item(), 'aff_loss': aff_loss.item()})\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b726a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f0b151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3681df02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d403f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be472ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f822a40c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69986df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a9162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bafb15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
